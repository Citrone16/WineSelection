{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificazione della qualità del vino\n",
    "Per la classificazione delle diverse tipologie di vino abbiamo effettuato un confronto tra i diversi modelli di _apprendimento supervisionato_ con l'obbiettivo di trovare il classificatore migliore in grado di determinare il valore più attendibile per il confronto della qualità\n",
    "\n",
    "Importiamo i moduli e le librerie utili alla realizzazione del sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab \n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone, ClassifierMixin\n",
    "from sklearn import metrics, tree, linear_model\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler, PolynomialFeatures, MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, cross_val_predict, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, matthews_corrcoef\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay \n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load del dataset\n",
    "Carichiamo il dataset in locale e lo visualizziamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File Dataset/wine_quality.csv does not exist: 'Dataset/wine_quality.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-157fb05ee493>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dataset/wine_quality.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File Dataset/wine_quality.csv does not exist: 'Dataset/wine_quality.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset/wine_quality.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulizia dei dati\n",
    "## Controllo e pulizia dei valori nulli\n",
    "Controlliamo la possibile presenza di valori nulli ed eventualmente eliminarli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimina le righe che contengono valori nulli\n",
    "df.dropna(axis='index', how='any', inplace=True)\n",
    "\n",
    "# heatmap per valori nulli\n",
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dimensione del dataset processato: ', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rimozione delle tuple duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.reset_index()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizzazione delle feature numeriche e categoriche\n",
    "Selezioniamo le features di interesse normalizziamo il dataset utilizzando la Normalizzazione Min-Max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "\n",
    "for i in df[features]:\n",
    "    df[i] = (df[i] - df[i].min()) / (df[i].max() - df[i].min())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trasformiamo la classe 'type' in una feature numerica utilizzando il label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "df[\"color\"] = ord_enc.fit_transform(df[[\"type\"]]) # assume 1 se bianco 0 se rosso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracciamo una Heatmap per rappresentare la correlazione tra le features prese in considerazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df[features].corr(), cbar=True, square=True, fmt = '.1f', annot = True, annot_kws={'size':8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Label\n",
    "Creiamo la quality label basata sulla già esistente colonna 'quality'\n",
    "\n",
    "- bad per un punteggio minore o uguale di 5\n",
    "- good per più di 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality_label'] = df.quality.apply(lambda q: 'bad' if q <= 5 else 'good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuzione della classe quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osserviamo la correlazione tra la qualità del vino e la percentuale alcolica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "sns.barplot(x = 'quality', y = 'alcohol', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizziamo la classe LabelEncoder per poter convertire la colonna  'quality_label' in feature numerica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "df[\"quality_label\"] = ord_enc.fit_transform(df[[\"quality_label\"]]) # assume 1 se bianco 0 se rosso\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Costruzione dei modelli & Addestramento\n",
    "## Preparazione del dataset\n",
    "Prenderemo come target la colonna 'color' per una maggiore accuratezza. Avendo già convertito questo attributo categorico utilizzando la classe LabelEncoder, possiamo procedere alla costruzione dei vari modelli di classificazione ed addestramento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df['color'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisione del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividiamo ora il dataset in train e test considerando soltanto le feature che hanno più importanza, come ad esempio il pH, lo zucchero residuo e la densità. Così facendo viene ridotta la complessità dei vari modelli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['type','quality_label','quality','pH','residual sugar','density'], axis = 1)\n",
    "y = df['quality_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modello Lineare\n",
    "Come primo modello utilizziamo la regressione lineare, che è un modello lineare per la classificazione piuttosto che la regressione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "#Calcolo il coefficiente angolare\n",
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Questo è il valore di R^2\n",
    "regr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.plot.scatter(x = 'quality', y = 'alcohol')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutiamo le prestazioni del modello e visualizziamo i risultati\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "Tramite questo classificatore possiamo calcolare la probabilità che un determinato evento avvenga all'interno del dataset. La costruzione del classificatore avviene nel seguente modo: si crea un oggetto della classe GaussianNB e successivamente viene chiamato il metodo fit, specificando come argomenti le osservazioni e le corrispondenti etichette. Infine invochiamo il metodo predict passando come argomento una lista di oggetti da classificare.\n",
    "\n",
    "Creiamo un pipeline dove vengono svolte in maniere consequenziale le seguenti azioni:\n",
    "\n",
    "- SMOTE un'operazione di l'oversampling sul set di training\n",
    "- Scaler un'operazione di normalizzazione\n",
    "- Classifier è il modello che verrà utilizzito per l'apprendimento, in questo caso Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = imbpipeline(steps = [['smote', SMOTE(random_state=5)],\n",
    "                                ['scaler', MinMaxScaler()],\n",
    "                                ['classifier', GaussianNB()]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=3,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in param_grid sono definiti gli iperparametri\n",
    "param_grid = {}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=stratified_kfold,\n",
    "                           verbose = 1,\n",
    "                           n_jobs=-1) # utilizzerà tutti i processori disponibili\n",
    "# troviamo il modello migliore\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "cv_score = grid_search.best_score_\n",
    "\n",
    "# effetuamo la predizione sul set di test\n",
    "y_test_predict = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcoliamo le metriche di valutazione\n",
    "accuracy = accuracy_score(y_test, y_test_predict)\n",
    "precision = precision_score(y_test, y_test_predict, average='macro')\n",
    "recall = recall_score(y_test, y_test_predict, average='macro')\n",
    "f1 = f1_score(y_test, y_test_predict, average='macro')\n",
    "mcc = matthews_corrcoef(y_test, y_test_predict)\n",
    "gm = geometric_mean_score(y_test, y_test_predict, average='macro')\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, \n",
    "                                        y_test_predict, \n",
    "                                        cmap=plt.cm.Blues)\n",
    "\n",
    "print(f'accuracy: {accuracy}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'f1: {f1}')\n",
    "print(f'matthews_corrcoef: {mcc}')\n",
    "print(f'geometric_mean_score: {gm}')\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_list = []\n",
    "scoring_list.append(dict([\n",
    "    ('Model', 'Naive Bayes'),\n",
    "    ('Train Accuracy', round(cv_score, 3)),\n",
    "    ('Test Accuracy', round(accuracy, 3)),\n",
    "    ('Precision', round(precision, 3)),\n",
    "    ('Recall', round(recall, 3)),\n",
    "    ('F1', round(f1, 3)),\n",
    "    ('Matthews Corrcoef', round(mcc,3)),\n",
    "    ('Geometric Mean Score', round(gm, 3))\n",
    "     ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Useremo il Random Forest della libreria scikit-learn, che calcola la media della previsione probabilistica di tutti gli alberi nella foresta per la previsione finale invece di prendere i voti di previsione effettivi e quindi calcolarne la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = imbpipeline(steps = [['smote', SMOTE(random_state=11)],\n",
    "                                ['scaler', MinMaxScaler()],\n",
    "                                ['classifier', RandomForestClassifier(max_depth=12, random_state=11)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=3,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in param_grid sono definiti gli iperparametri\n",
    "param_grid = {\n",
    "                'n_estimators': [50,100, 200],\n",
    "                'max_depth': [6,10, 12]\n",
    "                }\n",
    "\n",
    "new_params = {'classifier__' + key: param_grid[key] for key in param_grid}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=new_params,\n",
    "                           scoring='accuracy',\n",
    "                           cv=stratified_kfold,\n",
    "                           verbose = 5,\n",
    "                           n_jobs=-1) # utilizzerà tutti i processori disponibili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ricerca dei parametri migliori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# troviamo il modello migliore\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "cv_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(f'Best parameters: {best_params}')\n",
    "print(f'Cross-validation score: {cv_score}')\n",
    "\n",
    "# effetuamo la predizione sul set di test\n",
    "y_test_predict = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcoliamo le metriche di valutazione\n",
    "accuracy = accuracy_score(y_test, y_test_predict)\n",
    "precision = precision_score(y_test, y_test_predict, average='macro')\n",
    "recall = recall_score(y_test, y_test_predict, average='macro')\n",
    "f1 = f1_score(y_test, y_test_predict, average='macro')\n",
    "mcc = matthews_corrcoef(y_test, y_test_predict)\n",
    "gm = geometric_mean_score(y_test, y_test_predict, average='macro')\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, \n",
    "                                        y_test_predict, \n",
    "                                        cmap=plt.cm.Blues)\n",
    "\n",
    "print(f'accuracy: {accuracy}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'f1: {f1}')\n",
    "print(f'matthews_corrcoef: {mcc}')\n",
    "print(f'geometric_mean_score: {gm}')\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_list.append(dict([\n",
    "    ('Model', 'RandomForest'),\n",
    "    ('Train Accuracy', round(cv_score, 3)),\n",
    "    ('Test Accuracy', round(accuracy, 3)),\n",
    "    ('Precision', round(precision, 3)),\n",
    "    ('Recall', round(recall, 3)),\n",
    "    ('F1', round(f1, 3)),\n",
    "    ('Matthews Corrcoef', round(mcc,3)),\n",
    "    ('Geometric Mean Score', round(gm, 3))\n",
    "     ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = imbpipeline(steps = [['smote', SMOTE(random_state=11)],\n",
    "                                ['scaler', MinMaxScaler()],\n",
    "                                ['classifier',KNeighborsClassifier()]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=3,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ricerca dei parametri migliori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in param_grid sono definiti gli iperparametri\n",
    "param_grid = {\n",
    "         'n_neighbors': [10, 11, 12, 13] ,\n",
    "         'weights': ['distance'],\n",
    "         'algorithm' : ['ball_tree'], #, 'brute', 'auto',  'kd_tree', 'ball_tree']\n",
    "         'leaf_size': [12, 11, 13],\n",
    "         'p': [1]\n",
    "}\n",
    "\n",
    "\n",
    "new_params = {'classifier__' + key: param_grid[key] for key in param_grid}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=new_params,\n",
    "                           scoring='accuracy',\n",
    "                           cv=stratified_kfold,\n",
    "                           verbose = 5,\n",
    "                           n_jobs=-1) # utilizzerà tutti i processori disponibili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# troviamo il modello migliore\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "cv_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(f'Best parameters: {best_params}')\n",
    "print(f'Cross-validation score: {cv_score}')\n",
    "\n",
    "# effetuamo la predizione sul set di test\n",
    "y_test_predict = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcoliamo le metriche di valutazione\n",
    "accuracy = accuracy_score(y_test, y_test_predict)\n",
    "precision = precision_score(y_test, y_test_predict, average='macro')\n",
    "recall = recall_score(y_test, y_test_predict, average='macro')\n",
    "f1 = f1_score(y_test, y_test_predict, average='macro')\n",
    "mcc = matthews_corrcoef(y_test, y_test_predict)\n",
    "gm = geometric_mean_score(y_test, y_test_predict, average='macro')\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, \n",
    "                                        y_test_predict, \n",
    "                                        cmap=plt.cm.Blues)\n",
    "\n",
    "print(f'accuracy: {accuracy}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'f1: {f1}')\n",
    "print(f'matthews_corrcoef: {mcc}')\n",
    "print(f'geometric_mean_score: {gm}')\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_list.append(dict([\n",
    "    ('Model', 'KNN'),\n",
    "    ('Train Accuracy', round(cv_score, 3)),\n",
    "    ('Test Accuracy', round(accuracy, 3)),\n",
    "    ('Precision', round(precision, 3)),\n",
    "    ('Recall', round(recall, 3)),\n",
    "    ('F1', round(f1, 3)),\n",
    "    ('Matthews Corrcoef', round(mcc,3)),\n",
    "    ('Geometric Mean Score', round(gm, 3))\n",
    "     ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = imbpipeline(steps = [['smote', SMOTE(random_state=11)],\n",
    "                                ['scaler', MinMaxScaler()],\n",
    "                                ['classifier',SVC(kernel=None,\n",
    "                                                  gamma=None, \n",
    "                                                  C=None)]])\n",
    "stratified_kfold = StratifiedKFold(n_splits=3,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ricerca dei parametri migliori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in param_grid sono definiti gli iperparametri\n",
    "param_grid = {'C': [0.08, 0.1, 1, 10, 100], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf'] # linear\n",
    "              }\n",
    "\n",
    "new_params = {'classifier__' + key: param_grid[key] for key in param_grid}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=new_params,\n",
    "                           scoring='accuracy',\n",
    "                           cv=stratified_kfold,\n",
    "                           verbose = 5,\n",
    "                           n_jobs=-1) # utilizzerà tutti i processori disponibili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# troviamo il modello migliore\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "cv_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(f'Best parameters: {best_params}')\n",
    "print(f'Cross-validation score: {cv_score}')\n",
    "\n",
    "# effetuamo la predizione sul set di test\n",
    "y_test_predict = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcoliamo le metriche di valutazione\n",
    "accuracy = accuracy_score(y_test, y_test_predict)\n",
    "precision = precision_score(y_test, y_test_predict, average='macro')\n",
    "recall = recall_score(y_test, y_test_predict, average='macro')\n",
    "f1 = f1_score(y_test, y_test_predict, average='macro')\n",
    "mcc = matthews_corrcoef(y_test, y_test_predict)\n",
    "gm = geometric_mean_score(y_test, y_test_predict, average='macro')\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, \n",
    "                                        y_test_predict, \n",
    "                                        cmap=plt.cm.Blues)\n",
    "\n",
    "print(f'accuracy: {accuracy}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'f1: {f1}')\n",
    "print(f'matthews_corrcoef: {mcc}')\n",
    "print(f'geometric_mean_score: {gm}')\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_list.append(dict([\n",
    "    ('Model', 'SVM'),\n",
    "    ('Train Accuracy', round(cv_score, 3)),\n",
    "    ('Test Accuracy', round(accuracy, 3)),\n",
    "    ('Precision', round(precision, 3)),\n",
    "    ('Recall', round(recall, 3)),\n",
    "    ('F1', round(f1, 3)),\n",
    "    ('Matthews Corrcoef', round(mcc,3)),\n",
    "    ('Geometric Mean Score', round(gm, 3))\n",
    "     ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confronto dei vari modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=scoring_list)\n",
    "results = results[['Model',\n",
    "                   'Train Accuracy',\n",
    "                   'Test Accuracy',\n",
    "                   'Precision',\n",
    "                   'Recall',\n",
    "                   'F1',\n",
    "                   'Matthews Corrcoef',\n",
    "                   'Geometric Mean Score']]\n",
    "\n",
    "results = results.sort_values(by='Recall', ascending=False)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"darkgrid\"):\n",
    "    sns.barplot(data = results,\n",
    "                x=results['Model'],\n",
    "                y=results['Test Accuracy'],\n",
    "                palette = 'inferno').set(title = \"Confronto Classificatori - Test Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"darkgrid\"):\n",
    "    sns.barplot(data = results,\n",
    "                x=results['Model'],\n",
    "                y=results['Precision'],\n",
    "                palette = 'inferno').set(title = \"Confronto Classificatori - Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"darkgrid\"):\n",
    "    sns.barplot(data = results,\n",
    "                x=results['Model'],\n",
    "                y=results['Recall'],\n",
    "                palette = 'inferno').set(title = \"Confronto Classificatori - Recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come possiamo vedere dai grafici precedenti, il modello migliore è risultato il Random Forest con indice di profondità pari a 12. Nel complesso quasai tutti i modelli si sono comportati circa in egual modo, a differenza del Naive Bayes che ha restiuito un Accuracy del 70% circa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
